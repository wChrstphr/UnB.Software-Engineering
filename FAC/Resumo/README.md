# Resumo da Disciplina Fundamentos da Arquitetura de Computadores (FAC)

# √çndice  
1. [Hierarquia de Mem√≥ria](#1-hierarquia-de-mem√≥ria)  
2. [Mem√≥ria Virtual](#2-mem√≥ria-virtual)  
3. [Registradores](#3-registradores)  
4. [Cache](#4-cache)  
5. [RAM](#5-ram)  
6. [SSD (Unidade de Estado S√≥lido)](#6-ssd-unidade-de-estado-s√≥lido)  
7. [Barramentos](#7-barramentos)  
8. [Controladores de Mem√≥ria](#8-controladores-de-mem√≥ria)  
9. [Mapeamento de Mem√≥ria](#9-mapeamento-de-mem√≥ria)  
10. [Pagina√ß√£o](#10-pagina√ß√£o)  
11. [RISC (Reduced Instruction Set Computer)](#11-risc-reduced-instruction-set-computer)  
12. [CISC (Complex Instruction Set Computer)](#12-cisc-complex-instruction-set-computer)  
13. [Uniciclo](#13-uniciclo)  
14. [Multiciclo](#14-multiciclo)  
15. [Pipeline](#15-pipeline)  
16. [Hazards](#16-hazards)  
17. [Arquitetura de Von Neumann](#17-arquitetura-de-von-neumann)  

# 1. Hierarquia de Mem√≥ria
Organiza√ß√£o em camadas com diferentes caracter√≠sticas de velocidade, custo e capacidade. O topo da hierarquia (registradores, cache) √© mais r√°pido e caro, enquanto a base (HD/SSD) √© mais lenta e barata. Permite equilibrar desempenho e custo.

---

# 2. Mem√≥ria Virtual
T√©cnica que utiliza espa√ßo em disco (HD/SSD) para estender a capacidade da mem√≥ria RAM f√≠sica. Permite que programas utilizem mais mem√≥ria do que a dispon√≠vel fisicamente, atrav√©s da ilus√£o de um espa√ßo de endere√ßamento cont√≠guo maior.
- Programas usam **endere√ßos virtuais (VAs)**
- A **MMU (Memory Management Unit)** traduz VAs em endere√ßos f√≠sicos (PAs)

## Defini√ß√µes
- **Page size**: Tamanho fixo (ex: 4KB) das unidades transferidas entre disco e RAM
- **Address translation**: Mecanismo hardware/software para converter VA ‚Üí PA
- **Page table**: Estrutura hier√°rquica que mapeia p√°ginas virtuais em quadros f√≠sicos
- **TLB (Translation Lookaside Buffer)**: Cache de tradu√ß√µes recentes para acelerar o processo
---

# 3. Registradores
Mem√≥ria interna ao processador (CPU), com acesso em 1 ciclo de clock. Caracter√≠sticas:
- Velocidade m√°xima (nanossegundos)
- Capacidade extremamente limitada (ex: 32 registradores de 64 bits)
- Alto custo por bit
---

# 4. Cache
Mem√≥ria SRAM que armazena dados/instru√ß√µes frequentemente acessados. Hierarquia:
- **L1**: Integrada ao n√∫cleo (1-4 ciclos de acesso)
- **L2**: Compartilhada entre n√∫cleos (10-20 ciclos)
- **L3**: Cache √∫ltima n√≠vel (20-60 ciclos)
Reduz o *gap* de velocidade entre CPU e RAM (Efeito de Localidade F√≠sica).
---

# 5. RAM
Mem√≥ria DRAM vol√°til de acesso aleat√≥rio onde programas e dados s√£o armazenados enquanto o computador est√° ligado. Caracter√≠sticas:
- Armazena dados em uso durante a execu√ß√£o
- Acesso em ~100ns (mais lenta que cache)
- Capacidade t√≠pica: 4GB-128GB
- Organizada em m√≥dulos (DIMMs/SO-DIMMs)
---

# 6. SSD (Unidade de Estado S√≥lido)  
Armazenamento n√£o vol√°til baseado em mem√≥ria flash NAND, que combina alta velocidade com persist√™ncia de dados. Atua como camada intermedi√°ria entre RAM (vol√°til) e HDD (mec√¢nico), otimizando o desempenho do sistema

---

# 7. Barramentos  
Sistema de interconex√£o que permite a comunica√ß√£o entre componentes do computador atrav√©s de vias f√≠sicas. Atuam como canais de transmiss√£o coordenada de dados, endere√ßos e sinais de controle.  

## Tipos de Linhas  
1. **Linhas de Controle**  
   - Gerenciam opera√ß√µes do sistema:  
     - Sinaliza√ß√£o de *read/write* para mem√≥ria e dispositivos de E/S  
     - Controle de interrup√ß√µes (*IRQ*) e *acknowledgement*  
     - Gerenciamento de acesso ao barramento (*bus request/grant*)  
     - Sincroniza√ß√£o via clock e reset  

2. **Linhas de Dados**  
   - Transferem informa√ß√µes entre componentes (CPU, mem√≥ria, perif√©ricos).  
   - Largura do barramento (ex: 32/64 bits) define a quantidade de bits transmitidos por ciclo.  

3. **Linhas de Endere√ßos**  
   - Especificam localiza√ß√µes f√≠sicas na mem√≥ria ou dispositivos.  
   - Tamanho define o espa√ßo endere√ß√°vel (ex: 32 bits ‚Üí 4GB).  


## Categorias de Barramentos  

### Barramento Paralelo  
- **Funcionamento**: Transmiss√£o simult√¢nea de m√∫ltiplos bits por vias separadas.  
- **Vantagens**:  
  - Alta taxa de transfer√™ncia em curtas dist√¢ncias (ex: PCI ‚Äì 133 MB/s).  
- **Desvantagens**:  
  - **Skew**: Dessincroniza√ß√£o de bits em longas dist√¢ncias.  
  - **Crosstalk**: Interfer√™ncia entre linhas adjacentes.  
  - Custo elevado (mais fios = maior complexidade).  
- **Aplica√ß√µes**:  
  - Barramentos legados (ISA, ATA).  

### Barramento Serial  
- **Funcionamento**: Transmiss√£o sequencial bit a bit, com codifica√ß√£o embarcada (ex: 8b/10b).  
- **Vantagens**:  
  - Menor interfer√™ncia e custo (menos fios).  
  - Escal√°vel para altas frequ√™ncias (ex: PCIe 5.0 ‚Äì ~128 GB/s por lane).  
  - Robustez em longas dist√¢ncias (ex: USB 3.2 at√© 2 metros).   
- **Aplica√ß√µes**:  
  - Barramentos modernos (PCIe, SATA, USB, Thunderbolt).  


## Compara√ß√£o T√©cnica  
| Caracter√≠stica       | Paralelo               | Serial                 |  
|----------------------|------------------------|------------------------|  
| **Velocidade**       | Alta (curtas dist√¢ncias)| Muito alta (largura de banda escal√°vel)|  
| **Custo**            | Alto (mais fios)       | Baixo (menos fios)     |  
| **Complexidade**     | Sincroniza√ß√£o cr√≠tica  | Gerenciamento de protocolo |  
| **Exemplos**         | PCI, DDR4              | PCIe 5.0, USB4        |  

---

# 8. Controladores de Mem√≥ria  
Circuitos especializados que gerenciam a comunica√ß√£o entre a CPU e os m√≥dulos de mem√≥ria (RAM, cache), garantindo sincroniza√ß√£o, integridade e efici√™ncia no acesso aos dados.

## Fun√ß√µes Principais  
1. **Gerenciamento de Temporiza√ß√£o**:  
2. **Tradu√ß√£o de Endere√ßos**:   
3. **Multi-Canal**:   
4. **Controle de Erros**:  
5. **Interfaceamento**:  

---

# 9. Mapeamento de Mem√≥ria  
Processo de tradu√ß√£o de endere√ßos virtuais (espa√ßo l√≥gico visto pelos processos) para endere√ßos f√≠sicos (localiza√ß√µes reais na RAM). Implementado via coopera√ß√£o entre hardware (MMU - Memory Management Unit) e sistema operacional.

## Mecanismos de Implementa√ß√£o  
1. **Pagina√ß√£o** (Predominante em sistemas modernos):  
   - Divis√£o da mem√≥ria em **p√°ginas virtuais** (espa√ßo l√≥gico, tamanho fixo: 4KB, 2MB) e **quadros f√≠sicos** (frames, mesmo tamanho das p√°ginas).  
   - **Page Table**: Estrutura hier√°rquica mantida pelo SO, mapeando p√°ginas ‚Üí quadros.  
     - Flags: Presente/Ausente, R/W, User/Supervisor.  
2. **Segmenta√ß√£o** (Obsoleto em sistemas gerais):  
   - Divis√£o l√≥gica (c√≥digo, dados, pilha) com tamanhos vari√°veis.  
   - Usa **Tabela de Segmentos**.

## Componentes Cr√≠ticos  
| Componente          | Fun√ß√£o                                                                 | Localiza√ß√£o              |  
|---------------------|-----------------------------------------------------------------------|--------------------------|  
| **TLB** (Translation Lookaside Buffer) | Cache de tradu√ß√µes recentes (Virtual Adress (VA) ‚Üí Physical Adress (PA)                     | Parte da MMU (CPU)       |  
| **Page Table**      | Mapeamento completo VA ‚Üí PA (incluindo p√°ginas em disco)              | Mem√≥ria principal (RAM) |  
| **Page Directory**  | Estrutura de n√≠vel superior em sistemas multi-n√≠vel                   | RAM                      |  


## Hierarquia de Acesso  
1. **TLB Hit** (‚âà1 ciclo):  
   - Tradu√ß√£o imediata via cache da MMU.  
   - 1-3 ns
2. **TLB Miss ‚Üí Page Table Walk** (‚âà10-100 ciclos):  
   - Consulta √† page table na RAM.  
   - ~100 ns  
3. **Page Fault** (‚âà10^6 ciclos):  
   - P√°gina ausente na RAM ‚Üí Carregamento do disco (SSD/HD).  
   - SSD: ~100 Œºs (100.000x mais lento que RAM) 
   - HD: ~10 ms (10.000.000x mais lento que RAM)  

---

# 10. Pagina√ß√£o  
T√©cnica de gerenciamento de mem√≥ria que divide o espa√ßo de endere√ßamento virtual em **p√°ginas** (unidades de tamanho fixo) e o espa√ßo f√≠sico em **quadros** (frames). Implementada via hardware (MMU) e sistema operacional, permite aloca√ß√£o din√¢mica e prote√ß√£o de mem√≥ria.

## **Principais Conceitos**  
1. **Page Table (Tabela de P√°ginas)**:  
   - Estrutura hier√°rquica que mapeia p√°ginas virtuais (VA) ‚Üí quadros f√≠sicos (PA).  
   - Cada entrada (*Page Table Entry - PTE*) cont√©m:  
     - **Bit de Presen√ßa**: Indica se a p√°gina est√° na RAM.  
     - **Bits de Permiss√£o**: R/W/X (leitura, escrita, execu√ß√£o).  
     - **Endere√ßo F√≠sico** (se presente).  

2. **TLB (Translation Lookaside Buffer)**:  
   - Cache de tradu√ß√µes VA‚ÜíPA recentes, acelerando acesso √† mem√≥ria.  

3. **Page Fault**:  
   - Interrup√ß√£o gerada quando uma p√°gina n√£o est√° na RAM.  
   - O SO carrega a p√°gina do disco (swap) e atualiza a tabela.  


## **Funcionamento**  
1. **Divis√£o da Mem√≥ria**:  
   - **P√°ginas Virtuais**: Tamanho fixo (ex: 4KB, 2MB, 1GB).  
   - **Quadros F√≠sicos**: Correspondem ao tamanho das p√°ginas.  

2. **Prote√ß√£o**:  
   - Cada processo tem sua pr√≥pria tabela de p√°ginas, garantindo isolamento.  
   - P√°ginas de processos diferentes podem mapear para o mesmo quadro f√≠sico (mem√≥ria compartilhada).  

3. **Demand Paging**:  
   - Apenas p√°ginas necess√°rias s√£o carregadas na RAM (n√£o "algumas por vez").  


## **Fluxo de Page Fault**  
1. Acesso a um VA n√£o mapeado na RAM.  
2. MMU detecta "bit de presen√ßa = 0" na PTE.  
3. Gera interrup√ß√£o de **page fault**.  
4. SO:  
   - Identifica a localiza√ß√£o da p√°gina no disco (swap file/pagefile.sys).  
   - Carrega a p√°gina em um quadro livre na RAM.  
   - Atualiza a PTE e TLB.  
   - Reinicia a instru√ß√£o que causou o fault.  



## **Vantagens**  
- **Efici√™ncia**: Aloca√ß√£o granular (evita desperd√≠cio por fragmenta√ß√£o externa).  
- **Seguran√ßa**: Isolamento entre processos (ex: processo A n√£o acessa p√°ginas do B).  
- **Flexibilidade**: Mem√≥ria virtual maior que a f√≠sica.  

---

# 11. RISC (Reduced Instruction Set Computer)  
Arquitetura de processadores que prioriza **instru√ß√µes simples e altamente otimizadas**, executadas em **1 ciclo de clock** na maioria dos casos. Projetada para efici√™ncia energ√©tica e desempenho previs√≠vel.

## Caracter√≠sticas T√©cnicas  
1. **Conjunto de Instru√ß√µes**:  
   - **Reduzido**: ~50-100 instru√ß√µes (ex: ADD, LOAD, STORE).  
   - **Tamanho Fixo**: Facilita *pipelining* (ex: 32 bits no ARMv8).  
2. **Efici√™ncia**:  
   - **Pipeline Profundo**: At√© 15 est√°gios (ex: ARM Cortex-A77).  
   - **Menos Transistores**: Design simplificado reduz consumo (ex: IoT devices).  
3. **Modelo de Execu√ß√£o**:  
   - **Load/Store**: Opera√ß√µes aritm√©ticas s√≥ em registradores.  
   - **Mem√≥ria**: Acessos via LOAD/STORE expl√≠citos.  



## Vantagens  
- **Velocidade**: CPI (Clocks Per Instruction) pr√≥ximo de 1.  
- **Energia**: Eficiente para dispositivos m√≥veis (ex: smartphones Apple Silicon).  
- **Previsibilidade**: Ideal para sistemas em tempo real.  



## Exemplos  
- ARM (Cortex, Neoverse)  
- RISC-V (open-source)  
- MIPS (aplica√ß√µes embarcadas)  

---

# 12. CISC (Complex Instruction Set Computer)  
Arquitetura que utiliza **instru√ß√µes complexas e multifuncionais**, capazes de realizar m√∫ltiplas opera√ß√µes em um √∫nico comando. Foco em reduzir o n√∫mero de instru√ß√µes por programa.

## Caracter√≠sticas T√©cnicas  
1. **Conjunto de Instru√ß√µes**:  
   - **Amplo**: ~300-500 instru√ß√µes (ex: x86 `REP MOVSB` copia blocos de mem√≥ria).  
   - **Tamanho Vari√°vel**: 1 a 15 bytes por instru√ß√£o (ex: x86).  
2. **Modos de Endere√ßamento**:  
   - Direto √† mem√≥ria (ex: `ADD [AX], BX`).  
3. **Microc√≥digo**:  
   - Instru√ß√µes complexas s√£o decompostas em micro-opera√ß√µes (ex: Intel desde Pentium Pro).  


## Vantagens  
- **Compacta√ß√£o de C√≥digo**: Menos instru√ß√µes por tarefa.  
- **Legado**: Suporte a software antigo (ex: DOS no x86 moderno).  


## Exemplos  
- x86 (Intel, AMD)  
- z/Architecture (IBM mainframes)  



## Compara√ß√£o T√©cnica  
| Crit√©rio               | RISC                              | CISC                              |  
|------------------------|-----------------------------------|-----------------------------------|  
| **Instru√ß√µes**         | Simples, ciclo √∫nico              | Complexas, multi-ciclo           |  
| **Uso de Mem√≥ria**     | Apenas LOAD/STORE                 | Opera√ß√µes diretas                 |  
| **Pipeline**           | Eficiente (est√°gios homog√™neos)   | Complexo (hazards frequentes)     |  
| **Custo de Hardware**  | Baixo (design simplificado)       | Alto (microc√≥digo, decoders)     |  
| **Energia**            | 0.1-2W (IoT/ARM)                  | 15-250W (servidores x86)         |  

---

# 13. Uniciclo  
Cada instru√ß√£o √© executada em um √∫nico ciclo de clock. Possui hardware mais simples, sem componentes complexos de controle de tempo de execu√ß√£o. O ciclo de clock √© longo para acomodar a instru√ß√£o mais demorada, o que limita a velocidade. O desempenho √© restrito pelo caminho cr√≠tico (critical path) do datapath, que define o tempo necess√°rio para a etapa mais lenta da execu√ß√£o.  

**Vantagens**:  
- Simplicidade de implementa√ß√£o  
- Facilidade de depura√ß√£o  
- Menor complexidade de controle  
- Consist√™ncia temporal (todas as instru√ß√µes t√™m lat√™ncia fixa)  

**Desvantagens**:  
- Baixa efici√™ncia (ciclo de clock ditado pela instru√ß√£o mais lenta)  

**Passos**:  
1. **Instruction Fetch**: Busca da instru√ß√£o na mem√≥ria (RAM ou cache).  
2. **Instruction Decode**: Decodifica√ß√£o da instru√ß√£o e identifica√ß√£o de operandos.  
3. **Execute**: Opera√ß√µes l√≥gicas/aritm√©ticas na ULA.  
4. **Memory Access**: Leitura/escrita em mem√≥ria.  
5. **Write Back**: Escrita do resultado no registrador de destino.  
6. **Atualiza√ß√£o do PC**: Determina√ß√£o do pr√≥ximo endere√ßo (PC + 4).  

---

# 14. Multiciclo  
Cada instru√ß√£o √© dividida em etapas executadas em ciclos de clock separados. Permite reutiliza√ß√£o de componentes do hardware (ex: ULA usada em m√∫ltiplas etapas) e ciclos de clock mais curtos. Controle sequencial centralizado.  

**Vantagens**:  
- Ciclo de clock otimizado (menor que o uniciclo)  
- Uso eficiente de hardware  
- Balanceamento de est√°gios  

**Desvantagens**:  
- Controle mais complexo (m√°quina de estados finitos)  
- Overhead de sincroniza√ß√£o entre est√°gios  

**Passos**:  
1. **Instruction Fetch**: Busca da instru√ß√£o.  
2. **Instruction Decode**: Decodifica√ß√£o e leitura de registradores.  
3. **Execute**: C√°lculo na ULA.  
4. **Memory Access**: Acesso a mem√≥ria (se necess√°rio).  
5. **Write Back**: Escrita no registrador.  
6. **Atualiza√ß√£o do PC**: Pr√≥xima instru√ß√£o.  

---

# 15. Pipeline  
T√©cnica que permite a execu√ß√£o paralela de m√∫ltiplas instru√ß√µes, sobrepondo suas etapas de processamento. Cada est√°gio do pipeline opera em uma instru√ß√£o diferente simultaneamente, aumentando a taxa de throughput.  

**Vantagens**:  
- Alto desempenho (IPC > 1 em condi√ß√µes ideais)  
- Efici√™ncia no uso de recursos  
- Escalabilidade (aumento de est√°gios melhora frequ√™ncia)  

**Desvantagens**:  
- Hazards (conflitos estruturais, de dados e de controle)  
- Overhead de sincroniza√ß√£o entre est√°gios  

**Passos**:  
1. **Instruction Fetch**: Busca da instru√ß√£o.  
2. **Instruction Decode**: Decodifica√ß√£o e leitura de registradores.  
3. **Execute**: Opera√ß√£o na ULA.  
4. **Memory Access**: Leitura/escrita em mem√≥ria.  
5. **Write Back**: Escrita no registrador.  
6. **Atualiza√ß√£o do PC**: Pr√≥xima instru√ß√£o.  

**Observa√ß√£o**: Apesar dos mesmos est√°gios do multiciclo, o pipeline permite que at√© 5 instru√ß√µes estejam em execu√ß√£o simult√¢nea (uma por est√°gio).  

---

# 16. Hazards  
Problemas que ocorrem em processadores pipeline quando instru√ß√µes dependentes ou conflitantes interferem na execu√ß√£o paralela. Podem causar stalls (paradas) ou resultados incorretos, reduzindo a efici√™ncia do pipeline.


## Tipos de Hazards  

### 1. **Hazard Estrutural**  
- **Causa**: Conflito por recursos f√≠sicos (ex: duas instru√ß√µes precisam da ULA simultaneamente).  
- **Exemplo**: Acesso simult√¢neo √† mem√≥ria de instru√ß√µes e dados se compartilharem o mesmo barramento.  
- **Solu√ß√£o**: Duplica√ß√£o de recursos (ex: Harvard Architecture) ou escalonamento.  

### 2. **Hazard de Dados**  
- Ocorre quando uma instru√ß√£o depende do resultado de outra ainda em execu√ß√£o.  
   - **RAW (Read After Write)**: Instru√ß√£o l√™ dado antes de ser escrito.  
   - **WAR (Write After Read)**: Instru√ß√£o escreve antes de outra ler.  
   - **WAW (Write After Write)**: Duas instru√ß√µes escrevem no mesmo registrador fora de ordem.  
- **Exemplo**:  
  ```asm  
  ADD R1, R2, R3  
  SUB R4, R1, R5  // RAW: SUB depende do resultado de ADD  

---

# 17. Arquitetura de Von Neumann  
Modelo de computa√ß√£o que integra CPU, mem√≥ria e dispositivos de E/S atrav√©s de um **barramento √∫nico** para dados e instru√ß√µes. Fundamentada no conceito de **programa armazenado** (instru√ß√µes e dados na mesma mem√≥ria).

## Componentes Principais  
1. **CPU**:  
   - **ULA (Unidade L√≥gica Aritm√©tica)**: Executa opera√ß√µes matem√°ticas.  
   - **Unidade de Controle**: Coordena fluxo de dados e instru√ß√µes.  
   - **Registradores**: Armazenamento tempor√°rio de alta velocidade (ex: PC, AC).  

2. **Mem√≥ria Principal (RAM)**:  
   - Armazena instru√ß√µes e dados de forma n√£o diferenciada.  
   - Acesso sequencial via barramento compartilhado.  

3. **Barramento √önico**:  
   - Canal de comunica√ß√£o para transfer√™ncia de dados e instru√ß√µes.  


## Princ√≠pios de Opera√ß√£o  
- **Ciclo Fetch-Decode-Execute**:  
  1. Busca da instru√ß√£o na mem√≥ria.  
  2. Decodifica√ß√£o pela unidade de controle.  
  3. Execu√ß√£o na ULA.  


## Vantagens  
- **Simplicidade**: Projeto unificado facilita implementa√ß√£o.  
- **Flexibilidade**: Programas podem ser modificados dinamicamente.  


## Limita√ß√µes  
- **Gargalo de Von Neumann**:  
  - Competi√ß√£o pelo barramento √∫nico entre opera√ß√µes de leitura de instru√ß√µes e acesso a dados.  
  - Limita√ß√£o te√≥rica de throughput (ex: CPUs modernas perdem ~40% de desempenho devido a stalls).  

---

## Evolu√ß√£o Moderna  
- **Cache Hier√°rquico**: Minimiza acesso √† RAM (n√£o presente no modelo original).  
- **Pipeline**: Paraleliza est√°gios de execu√ß√£o.  
- **Arquiteturas H√≠bridas**: Uso de barramentos separados para dados/instru√ß√µes em n√≠vel de cache (ex: Harvard modificada).  

## Impacto Hist√≥rico  
- Base para todos os computadores de prop√≥sito geral p√≥s-1945 (ex: EDVAC, IAS Machine).  
- Influenciou projetos mesmo em sistemas com elementos Harvard (ex: ARM Cortex-M).  


---

*Com ‚ù§Ô∏è e üìö por Christopher (https://github.com/wChrstphr)*